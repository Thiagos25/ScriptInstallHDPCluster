————————————————————
*** Hadoop HDFS Testing ***
————————————————————

TestDFSIO Tests

# these tests must be run as the ‘hdfs’ user.  Login as root and “su - hdfs”

    su - hdfs

# set the $YARN_EXAMPLES to the current hdp library path

    export YARN_EXAMPLES=$YARN_HOME/usr/hdp/current/hadoop-mapreduce-client/

# Run the command to perform write testing

    yarn jar $YARN_EXAMPLES/hadoop-mapreduce-client-jobclient-tests.jar TestDFSIO -D mapred.output.compress=false -write -nrFiles 100 -fileSize 100

After the “-write” command finishes, you will see the output of the write speed across HDFS.  For example:
17/08/18 01:10:33 INFO fs.TestDFSIO: ----- TestDFSIO ----- : write
17/08/18 01:10:33 INFO fs.TestDFSIO:    	Number of files: 100
17/08/18 01:10:33 INFO fs.TestDFSIO: Total MBytes processed: 1000.0
17/08/18 01:10:33 INFO fs.TestDFSIO:  	Throughput mb/sec: 32.02049311559398
17/08/18 01:10:33 INFO fs.TestDFSIO: Average IO rate mb/sec: 33.11497116088867
17/08/18 01:10:33 INFO fs.TestDFSIO:  IO rate std deviation: 6.400035358623932
17/08/18 01:10:33 INFO fs.TestDFSIO: 	Test exec time sec: 35.364

# Run the command to perform read testing

    yarn jar $YARN_EXAMPLES/hadoop-mapreduce-client-jobclient-tests.jar TestDFSIO -D mapred.output.compress=false -read -nrFiles 100 -fileSize 100

After the “-read” command finishes, you will see the output of the write speed across HDFS.  For example:
17/08/18 01:12:18 INFO fs.TestDFSIO: ----- TestDFSIO ----- : read
17/08/18 01:12:18 INFO fs.TestDFSIO:    	Number of files: 100
17/08/18 01:12:18 INFO fs.TestDFSIO: Total MBytes processed: 1000.0
17/08/18 01:12:18 INFO fs.TestDFSIO:  	Throughput mb/sec: 208.76826722338205
17/08/18 01:12:18 INFO fs.TestDFSIO: Average IO rate mb/sec: 394.29290771484375
17/08/18 01:12:18 INFO fs.TestDFSIO:  IO rate std deviation: 216.1970884419439
17/08/18 01:12:18 INFO fs.TestDFSIO: 	Test exec time sec: 31.138

After finished with -write and -read, you will want to use “-clean” to free up the disk space again.  For example:
    yarn jar $YARN_EXAMPLES/hadoop-mapreduce-client-jobclient-tests.jar TestDFSIO -D mapred.output.compress=false -clean


Terasort
    su - hdfs
    export YARN_EXAMPLES=$YARN_HOME/usr/hdp/current/hadoop-mapreduce-client/

This example will generate 1,000,000 100 byte records as input for Terasort

    yarn jar $YARN_EXAMPLES/hadoop-mapreduce-examples.jar teragen -D mapred.output.compress=false 1000000 /benchmarks/terasort/terasort-input

Sort the records generated by TeraGen; ‘n’ should be number of reducer.  You may need to discover what number of reduce tasks based on number of nodes, number of CPU/cores per node, and/or amount of data being sorted.  For a typical 4-node cluster, the number of reducers may be between 2 and 8.

    yarn jar $YARN_EXAMPLES/hadoop-mapreduce-examples.jar terasort -D mapred.output.compress=false -Dmapred.reduce.tasks=<n> /benchmarks/terasort/terasort-input /benchmarks/terasort/terasort-output

In the output of the terasort results, you will see 2 lines that show the number of seconds required to perform the map and reduce tasks, for example:
Total time spent by all map tasks (ms)=11779
Total time spent by all reduce tasks (ms)=69389

Validate that the sort was successful and correct
    yarn jar $YARN_EXAMPLES/hadoop-mapreduce-examples.jar teravalidate -D mapred.output.compress=false /benchmarks/terasort/terasort-output /benchmarks/terasort/teravalidate-output
